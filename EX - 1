EXP - 1
    import numpy as np

# Step 1: Define the activation function
def step_function(value):
    return 1 if value >= 0 else 0

# Step 2: Create the Perceptron class
class Perceptron:
    def __init__(self, input_size, learning_rate=0.1):
        # Initialize weights (including one for bias)
        self.weights = np.zeros(input_size + 1)
        self.learning_rate = learning_rate

    # Method to make predictions
    def predict(self, inputs):
        # Add bias input (1 at the beginning)
        inputs_with_bias = np.insert(inputs, 0, 1)
        # Weighted sum
        total = np.dot(self.weights, inputs_with_bias)
        # Apply activation
        return step_function(total)

    # Method to train the perceptron
    def train(self, X, y, epochs=10):
        for epoch in range(epochs):
            print(f"\nEpoch {epoch+1}")
            for i in range(len(X)):
                prediction = self.predict(X[i])
                error = y[i] - prediction
                x_with_bias = np.insert(X[i], 0, 1)
                self.weights += self.learning_rate * error * x_with_bias
                print(f"Input: {X[i]}, Predicted: {prediction}, Actual: {y[i]}, Updated Weights: {self.weights}")

# Step 3: Example usage
if __name__ == "__main__":
    # Training data for OR gate
    X = np.array([
        [0, 0],
        [0, 1],
        [1, 0],
        [1, 1]
    ])
    y = np.array([0, 1, 1, 1])  # OR gate output

    # Step 4: Train the Perceptron
    perceptron = Perceptron(input_size=2)
    perceptron.train(X, y, epochs=10)

    # Step 5: Test the trained Perceptron
    print("\nFinal Predictions:")
    for x in X:
        output = perceptron.predict(x)
        print(f"Input: {x}, Predicted Output: {output}")
