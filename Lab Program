EXP - 1
    import numpy as np

# Step 1: Define the activation function
def step_function(value):
    return 1 if value >= 0 else 0

# Step 2: Create the Perceptron class
class Perceptron:
    def __init__(self, input_size, learning_rate=0.1):
        # Initialize weights (including one for bias)
        self.weights = np.zeros(input_size + 1)
        self.learning_rate = learning_rate

    # Method to make predictions
    def predict(self, inputs):
        # Add bias input (1 at the beginning)
        inputs_with_bias = np.insert(inputs, 0, 1)
        # Weighted sum
        total = np.dot(self.weights, inputs_with_bias)
        # Apply activation
        return step_function(total)

    # Method to train the perceptron
    def train(self, X, y, epochs=10):
        for epoch in range(epochs):
            print(f"\nEpoch {epoch+1}")
            for i in range(len(X)):
                prediction = self.predict(X[i])
                error = y[i] - prediction
                x_with_bias = np.insert(X[i], 0, 1)
                self.weights += self.learning_rate * error * x_with_bias
                print(f"Input: {X[i]}, Predicted: {prediction}, Actual: {y[i]}, Updated Weights: {self.weights}")

# Step 3: Example usage
if __name__ == "__main__":
    # Training data for OR gate
    X = np.array([
        [0, 0],
        [0, 1],
        [1, 0],
        [1, 1]
    ])
    y = np.array([0, 1, 1, 1])  # OR gate output

    # Step 4: Train the Perceptron
    perceptron = Perceptron(input_size=2)
    perceptron.train(X, y, epochs=10)

    # Step 5: Test the trained Perceptron
    print("\nFinal Predictions:")
    for x in X:
        output = perceptron.predict(x)
        print(f"Input: {x}, Predicted Output: {output}")


EX - 2
    !pip install -q keras-tuner
    import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/DT Team -1/Student_performance_data _.csv')
print(df.columns.tolist())
    import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
import keras_tuner as kt

# Load Dataset
df = pd.read_csv('/content/drive/MyDrive/DT Team -1/Student_performance_data _.csv')

# Create binary target from 'GradeClass'
df['pass'] = (df['GradeClass'] >= 50).astype(int)

# Drop the original 'GradeClass' and the target column from features
X = df.drop(['GradeClass', 'pass', 'StudentID'], axis=1)  # Remove ID to avoid noise

# One-hot encode categorical features (e.g., Gender, Ethnicity, etc.)
X = pd.get_dummies(X)

# Target
y = df['pass']

# Normalize numeric features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Build model function for Keras Tuner
def build_model(hp):
    model = Sequential()
    model.add(Dense(units=hp.Int('units_input', min_value=16, max_value=128, step=16),
                    activation='relu',
                    input_shape=(X.shape[1],)))

    for i in range(hp.Int('num_layers', 1, 3)):
        model.add(Dense(units=hp.Int(f'units_{i}', min_value=16, max_value=128, step=16),
                        activation='relu'))

    model.add(Dense(1, activation='sigmoid'))

    model.compile(
        optimizer=keras.optimizers.Adam(
            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),
        loss='binary_crossentropy',
        metrics=['accuracy'])

    return model

# Set up Keras Tuner
tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    executions_per_trial=1,
    directory='my_dir',
    project_name='student_pass_predictor'
)

# Search for best model
tuner.search(X_train, y_train, epochs=30, validation_split=0.2, verbose=0)

# Retrieve best model
best_model = tuner.get_best_models(num_models=1)[0]

# Evaluate model on test set
test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)
print(f"\nâœ… Final Test Accuracy after tuning: {test_acc * 100:.2f}%")

# Classification Report
y_pred = (best_model.predict(X_test) > 0.5).astype(int)
print("\nðŸ“„ Classification Report:")
print(classification_report(y_test, y_pred))
